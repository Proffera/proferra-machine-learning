{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d120ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c628273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_excel('cleandata.xlsx')\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "df = df.drop(['Kode Paket', 'Tahun Anggaran', 'Nama Paket', 'Tanggal Pengumuman', 'LPSE', 'Nama Pemenang', 'Kontrak'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c07f731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\tf220\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Converting `np.inexact` or `np.floating` to a dtype is deprecated. The current result is `float64` which is not strictly correct.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\LENOVO\\tf220\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Converting `np.inexact` or `np.floating` to a dtype is deprecated. The current result is `float64` which is not strictly correct.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\LENOVO\\tf220\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Converting `np.inexact` or `np.floating` to a dtype is deprecated. The current result is `float64` which is not strictly correct.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Fill in missing values for numerical and categorical columns\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == np.number:\n",
    "        df[column] = df[column].fillna(df[column].median())\n",
    "    else:\n",
    "        df[column] = df[column].fillna(df[column].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59750224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function mengecek nilai missing value\n",
    "def cek_null(df):\n",
    "    col_na = df.isnull().sum().sort_values(ascending=True)\n",
    "    percent = col_na / len(df)\n",
    "    \n",
    "    missing_data = pd.concat([col_na, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    \n",
    "    if (missing_data[missing_data['Total'] > 0].shape[0] == 0):\n",
    "        print(\"Tidak ditemukan missing value pada dataset\")\n",
    "        \n",
    "    else:\n",
    "        print(missing_data[missing_data['Total'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0906bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tidak ditemukan missing value pada dataset\n"
     ]
    }
   ],
   "source": [
    "cek_null(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a7d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform label encoding for categorical variables\n",
    "le = LabelEncoder()\n",
    "categorical_columns = ['Kategori', 'Sumber Dana', 'Nama KLPD', 'Satker']\n",
    "for column in categorical_columns:\n",
    "    df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427590b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target (y)\n",
    "X = df.drop('Skor Total', axis=1)\n",
    "y = df['Skor Total']\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "387534b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "numerical_columns = ['HPS', 'PAGU']\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954ca4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca67f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92102407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 1222.7953 - mae: 14.9570 - mse: 1222.7953 - val_loss: 664.4351 - val_mae: 21.6963 - val_mse: 664.4351\n",
      "Epoch 2/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 254.3930 - mae: 12.5083 - mse: 254.3930 - val_loss: 172.7717 - val_mae: 10.4331 - val_mse: 172.7717\n",
      "Epoch 3/50\n",
      "2146/2146 [==============================] - 2s 935us/step - loss: 257.0757 - mae: 12.5909 - mse: 257.0757 - val_loss: 307.4518 - val_mae: 14.2461 - val_mse: 307.4518\n",
      "Epoch 4/50\n",
      "2146/2146 [==============================] - 2s 973us/step - loss: 224.4687 - mae: 11.8118 - mse: 224.4687 - val_loss: 185.2652 - val_mae: 10.8497 - val_mse: 185.2652\n",
      "Epoch 5/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 204.7471 - mae: 11.3541 - mse: 204.7471 - val_loss: 177.5476 - val_mae: 10.6102 - val_mse: 177.5476\n",
      "Epoch 6/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 185.2573 - mae: 10.8342 - mse: 185.2573 - val_loss: 167.9168 - val_mae: 10.3151 - val_mse: 167.9168\n",
      "Epoch 7/50\n",
      "2146/2146 [==============================] - 3s 1ms/step - loss: 174.8493 - mae: 10.5301 - mse: 174.8493 - val_loss: 172.7144 - val_mae: 10.4872 - val_mse: 172.7144\n",
      "Epoch 8/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 169.0759 - mae: 10.3634 - mse: 169.0759 - val_loss: 152.3541 - val_mae: 9.8327 - val_mse: 152.3541\n",
      "Epoch 9/50\n",
      "2146/2146 [==============================] - 2s 869us/step - loss: 162.1556 - mae: 10.1517 - mse: 162.1556 - val_loss: 151.0169 - val_mae: 9.8022 - val_mse: 151.0169\n",
      "Epoch 10/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 159.7343 - mae: 10.0911 - mse: 159.7343 - val_loss: 147.9635 - val_mae: 9.7029 - val_mse: 147.9635\n",
      "Epoch 11/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 153.8893 - mae: 9.9067 - mse: 153.8893 - val_loss: 147.5642 - val_mae: 9.7180 - val_mse: 147.5642\n",
      "Epoch 12/50\n",
      "2146/2146 [==============================] - 2s 999us/step - loss: 150.5260 - mae: 9.8056 - mse: 150.5260 - val_loss: 149.6956 - val_mae: 9.7822 - val_mse: 149.6956\n",
      "Epoch 13/50\n",
      "2146/2146 [==============================] - 2s 971us/step - loss: 147.6813 - mae: 9.7082 - mse: 147.6813 - val_loss: 158.5800 - val_mae: 10.0793 - val_mse: 158.5800\n",
      "Epoch 14/50\n",
      "2146/2146 [==============================] - 2s 923us/step - loss: 144.4110 - mae: 9.6157 - mse: 144.4110 - val_loss: 158.2419 - val_mae: 10.0407 - val_mse: 158.2419\n",
      "Epoch 15/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 141.2667 - mae: 9.5047 - mse: 141.2667 - val_loss: 134.6938 - val_mae: 9.2884 - val_mse: 134.6938\n",
      "Epoch 16/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 138.5147 - mae: 9.4043 - mse: 138.5147 - val_loss: 132.1979 - val_mae: 9.1920 - val_mse: 132.1979\n",
      "Epoch 17/50\n",
      "2146/2146 [==============================] - 2s 940us/step - loss: 134.5518 - mae: 9.2722 - mse: 134.5518 - val_loss: 132.1966 - val_mae: 9.1905 - val_mse: 132.1966\n",
      "Epoch 18/50\n",
      "2146/2146 [==============================] - 2s 967us/step - loss: 132.9667 - mae: 9.2272 - mse: 132.9667 - val_loss: 132.2413 - val_mae: 9.1582 - val_mse: 132.2413\n",
      "Epoch 19/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 132.0185 - mae: 9.1867 - mse: 132.0185 - val_loss: 131.8453 - val_mae: 9.1429 - val_mse: 131.8453\n",
      "Epoch 20/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 131.5548 - mae: 9.1674 - mse: 131.5548 - val_loss: 131.8179 - val_mae: 9.1293 - val_mse: 131.8179\n",
      "Epoch 21/50\n",
      "2146/2146 [==============================] - 2s 981us/step - loss: 131.6071 - mae: 9.1715 - mse: 131.6071 - val_loss: 133.5874 - val_mae: 9.2176 - val_mse: 133.5874\n",
      "Epoch 22/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 131.4783 - mae: 9.1664 - mse: 131.4783 - val_loss: 131.6822 - val_mae: 9.1374 - val_mse: 131.6822\n",
      "Epoch 23/50\n",
      "2146/2146 [==============================] - 3s 1ms/step - loss: 131.5339 - mae: 9.1651 - mse: 131.5339 - val_loss: 132.0548 - val_mae: 9.1195 - val_mse: 132.0548\n",
      "Epoch 24/50\n",
      "2146/2146 [==============================] - 3s 1ms/step - loss: 131.4410 - mae: 9.1604 - mse: 131.4410 - val_loss: 138.8696 - val_mae: 9.4145 - val_mse: 138.8696\n",
      "Epoch 25/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 131.6341 - mae: 9.1691 - mse: 131.6341 - val_loss: 132.6688 - val_mae: 9.2006 - val_mse: 132.6688\n",
      "Epoch 26/50\n",
      "2146/2146 [==============================] - 2s 857us/step - loss: 131.2998 - mae: 9.1660 - mse: 131.2998 - val_loss: 132.6143 - val_mae: 9.1963 - val_mse: 132.6143\n",
      "Epoch 27/50\n",
      "2146/2146 [==============================] - 2s 995us/step - loss: 131.6095 - mae: 9.1668 - mse: 131.6095 - val_loss: 132.6427 - val_mae: 9.1941 - val_mse: 132.6427\n",
      "Epoch 28/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 131.2449 - mae: 9.1576 - mse: 131.2449 - val_loss: 132.7065 - val_mae: 9.1498 - val_mse: 132.7065\n",
      "Epoch 29/50\n",
      "2146/2146 [==============================] - 3s 1ms/step - loss: 131.4521 - mae: 9.1674 - mse: 131.4521 - val_loss: 133.4149 - val_mae: 9.2294 - val_mse: 133.4149\n",
      "Epoch 30/50\n",
      "2146/2146 [==============================] - 3s 1ms/step - loss: 131.2463 - mae: 9.1563 - mse: 131.2463 - val_loss: 131.9313 - val_mae: 9.1166 - val_mse: 131.9313\n",
      "Epoch 31/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 131.1908 - mae: 9.1524 - mse: 131.1908 - val_loss: 131.9966 - val_mae: 9.1286 - val_mse: 131.9966\n",
      "Epoch 32/50\n",
      "2146/2146 [==============================] - 2s 916us/step - loss: 131.2417 - mae: 9.1592 - mse: 131.2417 - val_loss: 132.8812 - val_mae: 9.1799 - val_mse: 132.8812\n",
      "Epoch 33/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 131.1688 - mae: 9.1530 - mse: 131.1688 - val_loss: 133.4262 - val_mae: 9.2140 - val_mse: 133.4262\n",
      "Epoch 34/50\n",
      "2146/2146 [==============================] - 2s 904us/step - loss: 131.1487 - mae: 9.1514 - mse: 131.1487 - val_loss: 131.9386 - val_mae: 9.1193 - val_mse: 131.9386\n",
      "Epoch 35/50\n",
      "2146/2146 [==============================] - 2s 861us/step - loss: 131.2066 - mae: 9.1573 - mse: 131.2066 - val_loss: 131.9436 - val_mae: 9.1454 - val_mse: 131.9436\n",
      "Epoch 36/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 131.1529 - mae: 9.1520 - mse: 131.1529 - val_loss: 133.0806 - val_mae: 9.2108 - val_mse: 133.0806\n",
      "Epoch 37/50\n",
      "2146/2146 [==============================] - 2s 1ms/step - loss: 131.0022 - mae: 9.1497 - mse: 131.0022 - val_loss: 132.6326 - val_mae: 9.1628 - val_mse: 132.6326\n",
      "Epoch 38/50\n",
      "2146/2146 [==============================] - 2s 853us/step - loss: 131.0832 - mae: 9.1552 - mse: 131.0832 - val_loss: 131.6054 - val_mae: 9.1425 - val_mse: 131.6054\n",
      "Epoch 39/50\n",
      "2146/2146 [==============================] - 2s 846us/step - loss: 130.9240 - mae: 9.1485 - mse: 130.9240 - val_loss: 132.1346 - val_mae: 9.1599 - val_mse: 132.1346\n",
      "Epoch 40/50\n",
      "2146/2146 [==============================] - 2s 855us/step - loss: 131.0643 - mae: 9.1501 - mse: 131.0643 - val_loss: 131.9203 - val_mae: 9.1666 - val_mse: 131.9203\n",
      "Epoch 41/50\n",
      "2146/2146 [==============================] - 2s 834us/step - loss: 130.8504 - mae: 9.1411 - mse: 130.8504 - val_loss: 132.5074 - val_mae: 9.1888 - val_mse: 132.5074\n",
      "Epoch 42/50\n",
      "2146/2146 [==============================] - 2s 839us/step - loss: 130.8879 - mae: 9.1469 - mse: 130.8879 - val_loss: 132.0772 - val_mae: 9.1565 - val_mse: 132.0772\n",
      "Epoch 43/50\n",
      "2146/2146 [==============================] - 2s 840us/step - loss: 130.7562 - mae: 9.1387 - mse: 130.7562 - val_loss: 131.9652 - val_mae: 9.1580 - val_mse: 131.9652\n",
      "Epoch 44/50\n",
      "2146/2146 [==============================] - 2s 909us/step - loss: 130.9372 - mae: 9.1436 - mse: 130.9372 - val_loss: 132.0513 - val_mae: 9.1497 - val_mse: 132.0513\n",
      "Epoch 45/50\n",
      "2146/2146 [==============================] - 2s 941us/step - loss: 130.7709 - mae: 9.1396 - mse: 130.7709 - val_loss: 132.0998 - val_mae: 9.1632 - val_mse: 132.0998\n",
      "Epoch 46/50\n",
      "2146/2146 [==============================] - 2s 842us/step - loss: 130.8136 - mae: 9.1366 - mse: 130.8136 - val_loss: 131.7266 - val_mae: 9.1445 - val_mse: 131.7266\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2146/2146 [==============================] - 2s 865us/step - loss: 130.7789 - mae: 9.1392 - mse: 130.7789 - val_loss: 131.6743 - val_mae: 9.1526 - val_mse: 131.6743\n",
      "Epoch 48/50\n",
      "2146/2146 [==============================] - 2s 865us/step - loss: 130.7707 - mae: 9.1371 - mse: 130.7707 - val_loss: 132.3409 - val_mae: 9.1701 - val_mse: 132.3409\n",
      "Epoch 49/50\n",
      "2146/2146 [==============================] - 2s 875us/step - loss: 130.7595 - mae: 9.1342 - mse: 130.7595 - val_loss: 133.0806 - val_mae: 9.2077 - val_mse: 133.0806\n",
      "Epoch 50/50\n",
      "2146/2146 [==============================] - 2s 870us/step - loss: 130.8739 - mae: 9.1382 - mse: 130.8739 - val_loss: 132.3153 - val_mae: 9.1579 - val_mse: 132.3153\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3cdf2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 551us/step - loss: 132.3153 - mae: 9.1579 - mse: 132.3153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[132.3152618408203, 9.157934188842773, 132.3152618408203]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "848b4833",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3955dd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10472\\2762853023.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save the label encoder and the scaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label_encoder.joblib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'scaler.joblib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the label encoder and the scaler\n",
    "joblib.dump(le, 'label_encoder.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f239e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf220",
   "language": "python",
   "name": "tf220"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
